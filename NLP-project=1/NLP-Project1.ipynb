{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d160d05a-785e-4117-98b8-03c0287b2667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ABC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ABC\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "287e89b1-cf64-4757-918c-9603643f5e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train-shape: 26\n",
      "Y-Train-shape: 26\n",
      "X-Test-shape: 7\n",
      "Y-Test-shape: 7\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#Import All The Libraries\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Creating A DataSet\n",
    "reviews = [\"cooler.. excellent air flow and for this price. It's so amazing and unbelievable. Just love it fa\",\n",
    "            \"Best budget 2 fit cooler. Nice cooling\",\n",
    "            \"The quality is good but the power of air is decent\",\n",
    "            \"Very bad product it's a only a fan\",\n",
    "            \"Ok ok product\",\n",
    "            \"The cooler is really fantastic and provides good air flow. Highly recommended\",\n",
    "            \"Very good product\",\n",
    "            \"Very nice\",\n",
    "            \"Very bad cooler\",\n",
    "            \"Very good\",\n",
    "            \"Beautiful product good material and perfectly working\",\n",
    "            \"Awesome\",\n",
    "            \"Good\",\n",
    "            \"Wonderful product, Must buy\",\n",
    "            \"Nice air cooler, smart cool breeze producer\",\n",
    "            \"Awsm\",\n",
    "            \"Nice product 777\",\n",
    "            \"Great cooler..\",\n",
    "            \"kice product\",\n",
    "            \"Good 277m\",\n",
    "            \"Very nice product ???? ???m\",\n",
    "            \"Good product\",\n",
    "            \"Nice product with the reasonable price\",\n",
    "            \"I like it...fe\",\n",
    "            \"Very goodd\",\n",
    "            \"Good product\",\n",
    "            \"Good product kawaleti\",\n",
    "            \"Very good cooler amazing beautiful designs affordable price\",\n",
    "            \"Using since I months. Great experience.\",\n",
    "            \"Very good perfomance and nice look\",\n",
    "            \"Product ids good having strong thrust of air flow..Must boy\",\n",
    "            \"Very good ???\",\n",
    "            \"Bad quality\"\n",
    "                  ]\n",
    "\n",
    "#Data-PreProcessing\n",
    "def preprocess_text(text):\n",
    "    text=re.sub(r'\\d+','', text) #Remove numbers \n",
    "    text=text.translate(str.maketrans(\"\",\"\", string.punctuation)) #Remove punctuation\n",
    "    text=text.lower() #convert text to lowercase\n",
    "    text=' '.join([word for word in text.split() if word not in stopwords.words('english')]) #Remove stopwords\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    text=' '.join([lemmatizer.lemmatize(word) for word in text.split()]) # Lemmatization\n",
    "    return text\n",
    "\n",
    "#Apply preprocessing to each review\n",
    "preprocessed_reviews=[preprocess_text(review) for review in reviews]\n",
    "\n",
    "#Initialize TF-IDF vactorizer\n",
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "\n",
    "#Fit-Transform\n",
    "tfidf_matrix=tfidf_vectorizer.fit_transform(preprocessed_reviews)\n",
    "\n",
    "#convert TF-IDF matrix to DataFrame for Visualization (optional)\n",
    "tfidf_df=pd.DataFrame(tfidf_matrix.toarray(),columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "#Define the sentiment labels and their corresponding numerical values\n",
    "sentiment_mapping={\"positive\":1,\"Neural\":0,\"Negative\":-1}\n",
    "\n",
    "#Assign numerical labels to each review based on the sentiment\n",
    "y_train=[1,1,0,-1,0,1,1,1,-1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,-1]\n",
    "\n",
    "#Train-Test-Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(tfidf_df,y_train,test_size=0.2,random_state=42)\n",
    "print(\"X-Train-shape:\",len(x_train))\n",
    "print(\"Y-Train-shape:\",len(y_train))\n",
    "print(\"X-Test-shape:\",len(x_test))\n",
    "print(\"Y-Test-shape:\",len(y_test))\n",
    "\n",
    "#Initialize and train Logistic regression model\n",
    "logistic_regression=LogisticRegression()\n",
    "logistic_regression.fit(x_train,y_train)\n",
    "\n",
    "#predict sentiment labels for test data\n",
    "y_pred=logistic_regression.predict(x_test)\n",
    "\n",
    "#Evaluate maodel perfomance\n",
    "Accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "614cb9ca-d7d4-4bac-8e6b-17f5979252ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\"cooler.. excellent air flow and for this price. It's so amazing and unbelievable. Just love it fa\",\n",
    "            \"Best budget 2 fit cooler. Nice cooling\",\n",
    "            \"The quality is good but the power of air is decent\",\n",
    "            \"Very bad product it's a only a fan\",\n",
    "            \"Ok ok product\",\n",
    "            \"The cooler is really fantastic and provides good air flow. Highly recommended\",\n",
    "            \"Very good product\",\n",
    "            \"Very nice\",\n",
    "            \"Very bad cooler\",\n",
    "            \"Very good\",\n",
    "            \"Beautiful product good material and perfectly working\",\n",
    "            \"Awesome\",\n",
    "            \"Good\",\n",
    "            \"Wonderful product, Must buy\",\n",
    "            \"Nice air cooler, smart cool breeze producer\",\n",
    "            \"Awsm\",\n",
    "            \"Nice product 777\",\n",
    "            \"Great cooler..\",\n",
    "            \"kice product\",\n",
    "            \"Good 277m\",\n",
    "            \"Very nice product ???? ???m\",\n",
    "            \"Good product\",\n",
    "            \"Nice product with the reasonable price\",\n",
    "            \"I like it...fe\",\n",
    "            \"Very goodd\",\n",
    "            \"Good product\",\n",
    "            \"Good product kawaleti\",\n",
    "            \"Very good cooler amazing beautiful designs affordable price\",\n",
    "            \"Using since I months. Great experience.\",\n",
    "            \"Very good perfomance and nice look\",\n",
    "            \"Product ids good having strong thrust of air flow..Must boy\",\n",
    "            \"Very good ???\",\n",
    "            \"Bad quality\"\n",
    "                  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82175d39-75d9-4bda-8f16-771c13b17319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text=re.sub(r'\\d+','', text) #Remove numbers \n",
    "    text=text.translate(str.maketrans(\"\",\"\", string.punctuation)) #Remove punctuation\n",
    "    text=text.lower() #convert text to lowercase\n",
    "    text=' '.join([word for word in text.split() if word not in stopwords.words('english')]) #Remove stopwords\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    text=' '.join([lemmatizer.lemmatize(word) for word in text.split()]) # Lemmatization\n",
    "    return text\n",
    "#Apply preprocessing to each review\n",
    "preprocessed_reviews=[preprocess_text(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41bf94b0-4667-44ee-9c11-bda75f205b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    affordable       air   amazing  awesome  awsm       bad  beautiful  \\\n",
      "0     0.000000  0.266112  0.333565      0.0   0.0  0.000000   0.000000   \n",
      "1     0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "2     0.000000  0.379510  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "3     0.000000  0.000000  0.000000      0.0   0.0  0.592197   0.000000   \n",
      "4     0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "5     0.000000  0.270781  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "6     0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "7     0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "8     0.000000  0.000000  0.000000      0.0   0.0  0.788786   0.000000   \n",
      "9     0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "10    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.432894   \n",
      "11    0.000000  0.000000  0.000000      1.0   0.0  0.000000   0.000000   \n",
      "12    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "13    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "14    0.000000  0.309183  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "15    0.000000  0.000000  0.000000      0.0   1.0  0.000000   0.000000   \n",
      "16    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "17    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "18    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "19    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "20    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "21    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "22    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "23    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "24    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "25    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "26    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "27    0.451624  0.000000  0.403853      0.0   0.0  0.000000   0.403853   \n",
      "28    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "29    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "30    0.000000  0.291818  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "31    0.000000  0.000000  0.000000      0.0   0.0  0.000000   0.000000   \n",
      "32    0.000000  0.000000  0.000000      0.0   0.0  0.675487   0.000000   \n",
      "\n",
      "        best       boy    breeze  ...  reasonable  recommended     since  \\\n",
      "0   0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "1   0.455725  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  ...    0.000000     0.379566  0.000000   \n",
      "6   0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "7   0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "9   0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "12  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "13  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "14  0.000000  0.000000  0.433396  ...    0.000000     0.000000  0.000000   \n",
      "15  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "16  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "17  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "18  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "19  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "20  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "21  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "22  0.000000  0.000000  0.000000  ...    0.656398     0.000000  0.000000   \n",
      "23  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "24  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "25  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "26  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "27  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "28  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.456453   \n",
      "29  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "30  0.000000  0.409055  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "31  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "32  0.000000  0.000000  0.000000  ...    0.000000     0.000000  0.000000   \n",
      "\n",
      "       smart    strong    thrust  unbelievable     using  wonderful  working  \n",
      "0   0.000000  0.000000  0.000000      0.373022  0.000000   0.000000   0.0000  \n",
      "1   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "2   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "3   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "4   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "5   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "6   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "7   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "8   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "9   0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "10  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.4841  \n",
      "11  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "12  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "13  0.000000  0.000000  0.000000      0.000000  0.000000   0.555349   0.0000  \n",
      "14  0.433396  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "15  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "16  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "17  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "18  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "19  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "20  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "21  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "22  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "23  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "24  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "25  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "26  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "27  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "28  0.000000  0.000000  0.000000      0.000000  0.456453   0.000000   0.0000  \n",
      "29  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "30  0.000000  0.409055  0.409055      0.000000  0.000000   0.000000   0.0000  \n",
      "31  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "32  0.000000  0.000000  0.000000      0.000000  0.000000   0.000000   0.0000  \n",
      "\n",
      "[33 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Initialize TF-IDF vactorizer\n",
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "\n",
    "#Fit-Transform\n",
    "tfidf_matrix=tfidf_vectorizer.fit_transform(preprocessed_reviews)\n",
    "\n",
    "#convert TF-IDF matrix to DataFrame for Visualization (optional)\n",
    "tfidf_df=pd.DataFrame(tfidf_matrix.toarray(),columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e4fbed3-5037-43a7-8400-aee17cc78906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Define the sentiment labels and their corresponding numerical values\n",
    "sentiment_mapping={\"positive\":1,\"Neural\":0,\"Negative\":-1}\n",
    "\n",
    "#Assign numerical labels to each review based on the sentiment\n",
    "y_train=[1,1,0,-1,0,1,1,1,-1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,-1]\n",
    "\n",
    "#Train-Test-Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(tfidf_df,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "#Initialize and train Logistic regression model\n",
    "logistic_regression=LogisticRegression()\n",
    "logistic_regression.fit(x_train,y_train)\n",
    "\n",
    "#predict sentiment labels for test data\n",
    "y_pred=logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85182d2c-d2aa-426d-bedc-d34149e718f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train-shape: 26\n",
      "Y-Train-shape: 26\n",
      "X-Test-shape: 7\n",
      "Y-Test-shape: 7\n",
      "    affordable  air  amazing  awesome  awsm       bad  beautiful  best  boy  \\\n",
      "31         0.0  0.0      0.0      0.0   0.0  0.000000        0.0   0.0  0.0   \n",
      "15         0.0  0.0      0.0      0.0   1.0  0.000000        0.0   0.0  0.0   \n",
      "26         0.0  0.0      0.0      0.0   0.0  0.000000        0.0   0.0  0.0   \n",
      "17         0.0  0.0      0.0      0.0   0.0  0.000000        0.0   0.0  0.0   \n",
      "8          0.0  0.0      0.0      0.0   0.0  0.788786        0.0   0.0  0.0   \n",
      "9          0.0  0.0      0.0      0.0   0.0  0.000000        0.0   0.0  0.0   \n",
      "19         0.0  0.0      0.0      0.0   0.0  0.000000        0.0   0.0  0.0   \n",
      "\n",
      "    breeze  ...  reasonable  recommended  since  smart  strong  thrust  \\\n",
      "31     0.0  ...         0.0          0.0    0.0    0.0     0.0     0.0   \n",
      "15     0.0  ...         0.0          0.0    0.0    0.0     0.0     0.0   \n",
      "26     0.0  ...         0.0          0.0    0.0    0.0     0.0     0.0   \n",
      "17     0.0  ...         0.0          0.0    0.0    0.0     0.0     0.0   \n",
      "8      0.0  ...         0.0          0.0    0.0    0.0     0.0     0.0   \n",
      "9      0.0  ...         0.0          0.0    0.0    0.0     0.0     0.0   \n",
      "19     0.0  ...         0.0          0.0    0.0    0.0     0.0     0.0   \n",
      "\n",
      "    unbelievable  using  wonderful  working  \n",
      "31           0.0    0.0        0.0      0.0  \n",
      "15           0.0    0.0        0.0      0.0  \n",
      "26           0.0    0.0        0.0      0.0  \n",
      "17           0.0    0.0        0.0      0.0  \n",
      "8            0.0    0.0        0.0      0.0  \n",
      "9            0.0    0.0        0.0      0.0  \n",
      "19           0.0    0.0        0.0      0.0  \n",
      "\n",
      "[7 rows x 60 columns]\n",
      "[1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"X-Train-shape:\",len(x_train))\n",
    "print(\"Y-Train-shape:\",len(y_train))\n",
    "print(\"X-Test-shape:\",len(x_test))\n",
    "print(\"Y-Test-shape:\",len(y_test))\n",
    "\n",
    "print(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fdf5b93-8ec7-4749-8d02-436578735f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#Evaluate maodel perfomance\n",
    "Accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef24548-0bb3-4e1b-a9d2-4f614a609137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
